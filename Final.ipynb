{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NeoRedcraft/nlp-project-1/blob/main/Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrUtcDnczAIM"
      },
      "source": [
        "# Section 1: Introduction to the Problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZ0yvWxwzIxM"
      },
      "source": [
        "# Section 2: Dataset Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94glWNfc0S1v"
      },
      "source": [
        "## Section 2.1: Brief Description\n",
        "\n",
        "[Provide a brief description of the knowledge sources used (e.g., PDFs, web pages, text\n",
        "files, databases).]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSdjA5hp0cRc"
      },
      "source": [
        "## Section 2.2: Source of Documents\n",
        "\n",
        "[State the source of the documents and how they were collected. ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRL2ve580kfH"
      },
      "source": [
        "## Section 2.3: Dataset Structure\n",
        "\n",
        "[Explain the dataset structure (number of documents, file types, size, domains).]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986
        },
        "id": "o7NphzFnDeWi",
        "outputId": "bdc6db94-d17f-41b3-b46e-705f52c1325f"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/dataset/Mental_Health_FAQ.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2392535419.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Load the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/dataset/Mental_Health_FAQ.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Initialize TF-IDF Vectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/dataset/Mental_Health_FAQ.csv'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/dataset/Mental_Health_FAQ.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Initialize TF-IDF Vectorizer\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = vectorizer.fit_transform(df['Questions'].dropna())\n",
        "\n",
        "# Get feature names and sum TF-IDF scores\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "dense = tfidf_matrix.todense()\n",
        "denselist = dense.tolist()\n",
        "df_tfidf = pd.DataFrame(denselist, columns=feature_names)\n",
        "top_n = 20\n",
        "tfidf_sum = df_tfidf.sum().sort_values(ascending=False).head(top_n)\n",
        "\n",
        "# Plot TF-IDF Bar Chart\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x=tfidf_sum.values, y=tfidf_sum.index, palette='viridis')\n",
        "plt.title(f'Top {top_n} Words in Questions by TF-IDF Score')\n",
        "plt.xlabel('TF-IDF Score')\n",
        "plt.ylabel('Words')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Add Explaination on Distrubition of both Question and Answer lengths\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OpHdVnt0qnE"
      },
      "source": [
        "## Section 2.4: Preprocessing\n",
        "\n",
        "[Discuss any preprocessing steps applied (cleaning, chunking strategy, token limits,\n",
        "metadata tagging, document filtering)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTlYQlly0yUM"
      },
      "source": [
        "## Section 2.5: Embedding Process\n",
        "\n",
        "[ Describe the embedding process (model used, chunk size, overlap).]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rag_preprocessing_code"
      },
      "outputs": [],
      "source": [
        "# RAG Preprocessing for Qwen/Qwen3 Model\n",
        "from langchain_community.document_loaders import CSVLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "\n",
        "# 1. Load Data\n",
        "loader = CSVLoader(file_path='dataset/Mental_Health_FAQ.csv', source_column='Questions', encoding='utf-8')\n",
        "documents = loader.load()\n",
        "\n",
        "# 2. Text Splitting\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "splits = text_splitter.split_documents(documents)\n",
        "\n",
        "# 3. Embedding Model (Preparing for Qwen Retrieval)\n",
        "embedding_model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
        "embeddings = HuggingFaceEmbeddings(model_name=embedding_model_name)\n",
        "\n",
        "# 4. Vector Store Creation\n",
        "persist_directory = './chroma_db'\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents=splits,\n",
        "    embedding=embeddings,\n",
        "    persist_directory=persist_directory\n",
        ")\n",
        "print(f'Vector store created successfully at {persist_directory} with {len(splits)} chunks.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YmtXAwEzPzc"
      },
      "source": [
        "# Section 3: Requirements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rcVZ26U1X91"
      },
      "source": [
        "## Section 3.1: LLM Frameworks\n",
        "\n",
        "[LLM frameworks (e.g., LangChain, LlamaIndex)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4tlaDhb1hxU"
      },
      "source": [
        "## Section 3.2: Embedding Model\n",
        "\n",
        "[Embedding models]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjztbdDC1vEl"
      },
      "source": [
        "## Section 3.3: Vector Database\n",
        "\n",
        "[Vector databases (e.g., FAISS, Chroma, Pinecone)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wW7p0yQ213Zc"
      },
      "source": [
        "## Section 3.4: Backend and UI tools\n",
        "\n",
        "[Backend and UI tools (Streamlit, Gradio)]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEB7bsYC2Cq1"
      },
      "source": [
        "## Section 3.5: Additional Utilities\n",
        "\n",
        "[Any additional utilities (PDF loaders, web scrapers, etc.)]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POS3F8vSzWu0"
      },
      "source": [
        "# Section 4: System Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PA4Dw25G2TVV"
      },
      "source": [
        "## Section 4.1: System Architecture\n",
        "\n",
        "[Describe the overall architecture (retriever, vector store, LLM, prompt template). ]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wt7_BodJ3sd3"
      },
      "source": [
        "## Section 4.2: Pipeline\n",
        "\n",
        "[Explain the pipeline (query \u2192 embedding \u2192 similarity search \u2192 context injection). ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qp_S2Rfo3y3o"
      },
      "source": [
        "## Section 4.3: Prompt Design and Grounding Strategy\n",
        "\n",
        "[Present prompt design and grounding strategy]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WG51n3Ci3-UQ"
      },
      "source": [
        "## Section 4.4: System Flow Diagram\n",
        "\n",
        "[Include System flow diagrams or pseudocode (if applicable) ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QCjEhn5zdFT"
      },
      "source": [
        "# Section 5: System Evaluation (Unseen Queries)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4w40kRSz48M0"
      },
      "source": [
        "## Section 5.1: Evaluation Setup\n",
        "\n",
        "[Describe the evaluation setup (manual testing, benchmark questions, user simulation). ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5_icsC35CEq"
      },
      "source": [
        "## Section 5.2: Report Metrics\n",
        "\n",
        "[Report relevant metrics (e.g., response relevance, accuracy, faithfulness, latency). ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTi6zcf_5HMt"
      },
      "source": [
        "## Section 5.3: Hallucination Handling\n",
        "\n",
        "[Discuss hallucination handling and failure cases. ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHqq_uT65eK3"
      },
      "source": [
        "## Section 5.4: Retrived Context vs. Final Generated Answers\n",
        "\n",
        "[Compare retrieved context vs. final generated answers]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdmISmkLzmvV"
      },
      "source": [
        "# Section 6 Web Deployment\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1LKmmrF8qu6"
      },
      "source": [
        "## Section 6.1: Streamlit Interface\n",
        "\n",
        "[Develop a Streamlit or Gradio interface. ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHnU0rrj81fa"
      },
      "source": [
        "## Section 6.2: User Input\n",
        "\n",
        "[Allow users to input questions or prompts]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZvZlmJW8_7x"
      },
      "source": [
        "## Section 6.3: Retrived Context\n",
        "\n",
        "[Display Retrived Context (optional but encouraged)]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEqIVtrc9IL6"
      },
      "source": [
        "## Section 6.4: Chatbot Response\n",
        "\n",
        "[Show chatbot Responses in real time]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaJSFwfdzxWE"
      },
      "source": [
        "# Section 7: Results and Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuOTqdt7_Tsq"
      },
      "source": [
        "## Section 7.1: Qualitative Results\n",
        "\n",
        "[Present qualitative results (sample Q&A interactions).\n",
        "] Discuss strengths, weaknesses, edge cases, and observed limitations. Analyze how retrieval quality affects response quality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKUXfBz6_ajy"
      },
      "source": [
        "## Section 7.2: Quantitative Results\n",
        "\n",
        "[Present quantitative or structured evaluation results (if applicable). ] Discuss strengths, weaknesses, edge cases, and observed limitations. Analyze how retrieval quality affects response quality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neK21Qtpz1lM"
      },
      "source": [
        "# Section 8: Documentation\n",
        "\n",
        "[Insert Link to the IEEE Paper]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yw6tshDfz4pN"
      },
      "source": [
        "# Section 9: Insights and conclusions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4val4_CABvq"
      },
      "source": [
        "[Summarize what your group learned about building a LLM chatbot. Discuss system strengths,\n",
        "limitations (e.g., retrieval errors, hallucinations), and propose areas for future improvement such\n",
        "as better embeddings, reranking, or hybrid retrieval.]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3OoJzqMz-VV"
      },
      "source": [
        "# Section 10: References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUqJchVeAIri"
      },
      "source": [
        "## Section 10.1: Scholarity Articles\n",
        "\n",
        "[Cite in APA format, and put a description of how you used it for your work]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRfzw-03AQZD"
      },
      "source": [
        "## Section 10.2: Online References\n",
        "\n",
        "[Put the website, blog, or article title, link, and how you incorporated it into your\n",
        "work]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1a72I7IAWy6"
      },
      "source": [
        "## Section 10.3: Artificial Intelligence Tools\n",
        "\n",
        "[Put the model used (e.g., ChatGPT, Gemini), the complete transcript of your\n",
        "conversations with the model (including your prompts and its responses), and a\n",
        "description of how you used it for your work]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMXsDgFJemf+Az2xNc0YhgI",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}